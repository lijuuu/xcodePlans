### **ğŸ”¥ Architecture Breakdown (Optimized for Latency & Scalability)**  

âœ… **Send HTTP request with `user_id` as `wss_session_id`**  
âœ… **NATS pub/sub for `code.run` (session-based execution requests)**  
âœ… **Worker Pool with concurrency control (limits workers per t3.micro)**  
âœ… **Prewarmed Firecracker VMs for ultra-low latency execution**  
âœ… **Dynamic VM health checks & replacement strategy**  
âœ… **Efficient WebSocket routing via session ID**  

---

### **ğŸš€ Execution Flow (Step-by-Step)**
1ï¸âƒ£ **Frontend sends execution request via HTTP**
   - `{ user_id, session_id, code, lang, ... }`
   - Backend validates, pushes to **NATS (`code.run`)**  

2ï¸âƒ£ **Code Execution Service subscribes to `code.run`**
   - Dequeues request
   - Calls `getFreeVM()` to assign a worker  
   - **Worker Pool limits concurrency** (e.g., max 5 workers per t3.micro)  

3ï¸âƒ£ **Firecracker VM executes code**
   - If VM is broken â†’ **replace it automatically**  
   - If no free VM â†’ **queue request (backpressure)**  

4ï¸âƒ£ **Worker sends output to WebSocket via session ID**
   - Backend sends `{ session_id, output, status }`  

5ï¸âƒ£ **Frontend WebSocket receives result in real-time**
   - UI updates instantly  

---

### **ğŸ”¥ Optimizations for Scaling**
ğŸ”¹ **Limit worker pool concurrency** â†’ Prevents t3.micro overload  
ğŸ”¹ **Prewarm Firecracker VMs** â†’ <10ms startup time  
ğŸ”¹ **Backpressure Handling** â†’ Queue tasks if workers are full  
ğŸ”¹ **Replace dead VMs dynamically** â†’ Ensures execution continuity  
ğŸ”¹ **NATS for async messaging** â†’ Low-latency task distribution  
ğŸ”¹ **WSS session ID routing** â†’ Avoids unnecessary open connections  

---

### **ğŸ›  Potential Issues & Fixes**
| **Issue**                 | **Fix**  |
|---------------------------|---------|
| Too many WebSocket connections? | Scale horizontally with **NATS JetStream + multiple backend instances** |
| Firecracker VMs crashing? | **Health check & auto-replace** broken VMs |
| Worker Pool saturation? | **Queue & rate-limit requests** |
| High latency on cold start? | **Prewarm VMs** and keep idle ones ready |
| User disconnects mid-execution? | **Store result for reconnection** or retry |
| t3.micro bottleneck? | **Upgrade instances or load balance execution** |

---

### **ğŸ”¥ Performance Estimations on t3.micro**
| **Component** | **Estimated Latency (ms)** |
|--------------|--------------------------|
| HTTP Request to Backend | 1-5 ms |
| NATS Publish to Worker | 1-3 ms |
| Worker Dequeuing Task | 1-5 ms |
| Firecracker Startup (Prewarmed) | <10 ms |
| Code Execution (Simple) | 20-50 ms |
| Code Execution (Heavy) | 100-500 ms |
| NATS Publish Result | 1-3 ms |
| WebSocket Transmission | 1-5 ms |
| **Total (Prewarmed Firecracker, Simple Code)** | **30-70 ms** |
| **Total (Cold Firecracker, Heavy Code)** | **200-800 ms** |

---

### **ğŸš€ Scaling Beyond t3.micro**
For **1M users, 10K concurrent requests**, you'd need:
- **Load balancing** (ALB, Nginx)
- **More instances (t3.large, c5.large)**
- **Distributed worker pool**
- **NATS JetStream for fault tolerance**

---

### **âœ… Final Verdict**
This setup is **fast, scalable, and efficient** ğŸš€  
Want to **see sample code for this?** ğŸ”¥
